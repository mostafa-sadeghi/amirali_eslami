{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPixBr3dpl9mrlMIchJOI/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-sadeghi/amirali_eslami/blob/main/adeep_look_on_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200219152207/new41.jpg\">"
      ],
      "metadata": {
        "id": "aSHCHhI61cRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model achieves 92.7% top-5 test accuracy on the ImageNet dataset which contains 14 million images belonging to 1000 classes. \n"
      ],
      "metadata": {
        "id": "EWOk_fYF1qSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG Architecture: The input to the network is an image of dimensions (224, 224, 3). The first two layers have 64 channels of a 3x3 filter size and the same padding. Then after a max pool layer of stride (2, 2), two layers have convolution layers of 128 filter size and filter size (3, 3). This is followed by a max-pooling layer of stride (2, 2) which is the same as the previous layer. Then there are 2 convolution layers of filter size (3, 3) and 256 filters. After that, there are 2 sets of 3 convolution layers and a max pool layer. Each has 512 filters of (3, 3) size with the same padding. This image is then passed to the stack of two convolution layers. In these convolution and max-pooling layers, the filters we use are of the size 3x3 instead of 11x11 in AlexNet and 7*7 in ZF-Net. In some of the layers, it also uses 1x1 pixel which is used to manipulate the number of input channels. There is a padding of 1-pixel (same padding) done after each convolution layer to prevent the spatial feature of the image."
      ],
      "metadata": {
        "id": "gJQB2v_u1rk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200219152327/conv-layers-vgg16.jpg\">"
      ],
      "metadata": {
        "id": "d32AU4bc1r6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the stack of convolution and max-pooling layer, we got a (7, 7, 512) feature map. We flatten this output to make it a (1, 25088) feature vector. After this there is 3 fully connected layer, the first layer takes input from the last feature vector and outputs a (1, 4096) vector, the second layer also outputs a vector of size (1, 4096) but the third layer output a 1000 channels for 1000 classes of ILSVRC challenge i.e. 3rd fully connected layer is used to implement softmax function to classify 1000 classes. All the hidden layers use ReLU as its activation function. ReLU is more computationally efficient because it results in faster learning and it also decreases the likelihood of vanishing gradient problems.\n",
        "\n",
        "Configuration: The table below listed different VGG architectures. We can see that there are 2 versions of VGG-16 (C and D). There is not much difference between them except for one that except for some convolution layers, (3, 3) filter size convolution is used instead of (1, 1). These two contain 134 million and 138 million parameters respectively."
      ],
      "metadata": {
        "id": "N8AT-0wp1sXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200217112031/VGG16conf.PNG\">"
      ],
      "metadata": {
        "id": "u90TCTie3H4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Localization In Image: To perform localization, we need to replace the class score by bounding box location coordinates. A bounding box location is represented by the 4-D vector (center coordinates(x,y), height, width). There are two versions of localization architecture, one is bounding box is shared among different candidates (the output is 4 parameter vector) and the other is a bounding box is class-specific (the output is 4000 parameter vector). The paper experimented with both approaches on VGG -16 (D) architecture. Here we also need to change loss from classification loss to regression loss functions (such as MSE) that penalize the deviation of predicted loss from the ground truth. \n",
        "\n",
        "Results: VGG-16 was one of the best performing architectures in the ILSVRC challenge 2014.It was the runner up in the classification task with a top-5 classification error of 7.32% (only behind GoogLeNet with a classification error of 6.66%). It was also the winner of localization task with 25.32% localization error.\n",
        "\n",
        "Limitations Of VGG 16:\n",
        "\n",
        "It is very slow to train (the original VGG model was trained on Nvidia Titan GPU for 2-3 weeks).\n",
        "The size of VGG-16 trained imageNet weights is 528 MB. So, it takes quite a lot of disk space and bandwidth which makes it inefficient.\n",
        "138 million parameters lead to exploding gradients problem.\n",
        "Further advancements: Resnets are introduced to prevent exploding gradients problem that occurred in VGG-16."
      ],
      "metadata": {
        "id": "1jQ0T-sX3HyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual Networks (ResNet) â€“ Deep Learning\n",
        "After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. "
      ],
      "metadata": {
        "id": "zjVEPCgM3HuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src =\"https://media.geeksforgeeks.org/wp-content/uploads/20200424200128/abc.jpg\">"
      ],
      "metadata": {
        "id": "w5i_sOWW4WwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. \n",
        "ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. \n",
        "\n",
        "Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. \n",
        "The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, \n",
        "\n",
        "F(x) := H(x) - x which gives H(x) := F(x) + x. "
      ],
      "metadata": {
        "id": "ApIBzxWZ4XKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200424011510/Residual-Block.PNG\">"
      ],
      "metadata": {
        "id": "FT4TZiiV4XfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization."
      ],
      "metadata": {
        "id": "vl7XGepf5a0y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KF1o0VGf5c0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}